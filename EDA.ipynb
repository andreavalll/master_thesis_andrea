{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "ff4a237b-1b02-421f-85ad-00c3506deb15"
   },
   "source": [
    "### Datasets\n",
    "Took both of these datasets from hugging face\n",
    "- GEST → Gender Stereotype dataset consisting of 3,565 user-generated sentences, each labeled with one of 16 distinct gender stereotype categories(e.g. “Men are strong”, “Women are submissive”).  Every sentence in GEST is tagged with one of these 16 categories, indicating the stereotype it represents.\n",
    "- StereoSet → Measures stereotypical biases across gender, profession, race, and religion.\n",
    "We focus on the gender subset of the dataset, which, after processing, consists of 726 sentences, each labeled as stereotype, anti-stereotype, or unrelated.\n",
    "These can be thought of as triples, so for the context: “The school girl is walking down the street” we have “She is a target for child predators” as stereotype, “The wind is blowing at 80 mph” as unrelated, and “She does not have to worry about child predators” as the antistereotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "f10a999f-456c-47b2-a0e4-0127ad5aafa5"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "05966f07-763e-4cd3-8581-e70408e78c15",
    "outputId": "d8da7454-e431-48aa-80a1-ba00d299a842"
   },
   "outputs": [],
   "source": [
    "# Stereoset dataset\n",
    "df_stereoset = pd.read_parquet(\"hf://datasets/McGill-NLP/stereoset/intersentence/validation-00000-of-00001.parquet\")\n",
    "df_stereoset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1101228e-3082-4aa0-9425-171193e9aa09",
    "outputId": "7bdda995-0649-4ca5-e694-113be3f8a05c"
   },
   "outputs": [],
   "source": [
    "# GEST dataset\n",
    "splits = {'gest1.0': 'gest.csv', 'gest1.1': 'gest_1.1.csv'}\n",
    "df_gest = pd.read_csv(\"hf://datasets/kinit/gest/\" + splits[\"gest1.0\"])\n",
    "df_gest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "d23bec2f-fe21-4c7f-8220-5b5fbe6d7c59"
   },
   "source": [
    "### Meaning of stereotype numbers:\n",
    "1. Women are emotional and irrational\n",
    "2. Women are gentle, kind, and submissive\n",
    "3. Women are empathetic and caring\n",
    "4. Women are neat and diligent\n",
    "5. Women are social\n",
    "6. Women are weak\n",
    "7. Women are beautiful\n",
    "8. Men are tough and rough\n",
    "9. Men are self-confident\n",
    "10. Men are professional\n",
    "11. Men are rational\n",
    "12. Men are providers\n",
    "13. Men are leaders\n",
    "14. Men are childish\n",
    "15. Men are sexual\n",
    "16. Men are strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be9e9225-922d-4674-8dce-f95e3ff0091a",
    "outputId": "13ebd48b-706f-404e-cc93-95ffe2b246d4"
   },
   "outputs": [],
   "source": [
    "df_stereoset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5c60755-a76c-40ed-9c57-82b4ef1d3063",
    "outputId": "dbdba355-5c3c-4c0f-9690-5d96ae608ffe"
   },
   "outputs": [],
   "source": [
    "df_gest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "25e68408-a522-4798-9dae-3d06e260b2ca"
   },
   "source": [
    "### 1. Filter StereoSet to only focus on the gender subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b4ba45b4-695f-48f1-8415-d162da3dd33c",
    "outputId": "7673a0e3-e99f-4114-cb83-bd937f33940d"
   },
   "outputs": [],
   "source": [
    "# Filtered dataset\n",
    "df_stereo_gender = df_stereoset[df_stereoset[\"bias_type\"] == \"gender\"]\n",
    "df_stereo_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61e82786-c42f-4398-af2d-fa9fe03b3c16",
    "outputId": "241d7a29-5f5e-4586-8465-e3366f39f723"
   },
   "outputs": [],
   "source": [
    "df_stereo_gender['sentences'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "95dc909f-7ae4-4cd7-91f9-93d2dd13f140"
   },
   "source": [
    "By inspecting the previous output, I can see:\n",
    "- 'sentence': a list of candidate sentences\n",
    "- 'labels': crowdworker evaluations\n",
    "- 'gold_label': official label (e.g., [2, 0, 1] → stereotype, unrelated, anti-stereotype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "ae3dda37-d97f-4c40-b568-b3b2d0e53aa0"
   },
   "source": [
    "### 2. One sentence per row with its label type: stereotype, anti-stereotype, unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "55230cb4-838c-4466-887c-7b69280da0a4"
   },
   "outputs": [],
   "source": [
    "# Mapping each sentence in sentences dict to its label type (stereotype, anti-stereotype, unrelated)\n",
    "label_map = {0: 'anti-stereotype', 1: 'stereotype', 2: 'unrelated'}\n",
    "flattened_rows = []\n",
    "\n",
    "for _, row in df_stereo_gender.iterrows():\n",
    "    sentences = row['sentences']['sentence']\n",
    "    labels = row['sentences']['gold_label']\n",
    "\n",
    "    for sentence, label in zip(sentences, labels):\n",
    "        flattened_rows.append({\n",
    "            'sentence': sentence,\n",
    "            'context': row['context'],\n",
    "            'label_type': label_map[label],\n",
    "            'bias_type': row['bias_type'],\n",
    "            'source': 'StereoSet'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b6d202fd-47f4-4eaa-8dab-db6449308a74",
    "outputId": "381c2591-2895-4da5-e399-948a3154fdfa"
   },
   "outputs": [],
   "source": [
    "df_stereo_flat = pd.DataFrame(flattened_rows)\n",
    "df_stereo_flat # augmented dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "00027797-b1f4-40f9-83db-99dca647ea09",
    "outputId": "6fa8149d-2793-4f15-b1a3-6f16162a59c2"
   },
   "outputs": [],
   "source": [
    "df_stereo_flat['label_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "8bcaa9a9-b9f2-431c-89c8-c6e7e046baa4"
   },
   "source": [
    "### 3. Making GEST dataset match the structure of StereoSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "69babff3-4281-4eaf-89af-1012f30c7c7f",
    "outputId": "ffe40863-3659-4b72-e80c-29b0e2cf918e"
   },
   "outputs": [],
   "source": [
    "df_gest_copy = df_gest.copy()\n",
    "df_gest_copy['label_type'] = 'stereotype'\n",
    "df_gest_copy['bias_type'] = 'gender'\n",
    "df_gest_copy['source'] = 'GEST'\n",
    "\n",
    "df_gest_clean = df_gest_copy[['sentence', 'stereotype', 'label_type', 'bias_type', 'source']]\n",
    "df_gest_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "66531749-ce32-4fd3-8429-397382c30f48"
   },
   "source": [
    "### 4. Merging the two datasets\n",
    "The 242 gender-stereotypical sentences from StereoSet will be manually mapped to one of the 16 GEST stereotype categories. Then, I will proceed to merge these datasets (3,807 rows in total).\n",
    "By merging them, I can increase the diversity of phrasings and contexts for each stereotype category, which can strengthen the robustness of my findings. GEST provides more formal, declarative stereotype statements, while StereoSet contributes some contextual and possibly conversational instances; together they cover a wider spectrum of ways a stereotype might appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "bed5aae8-d9e2-459a-8b6d-9e72ab0977ca"
   },
   "source": [
    "For this manual mapping I will be using Chat GPT for assistance (to speed up the process) but I will be supervising all of the mappings to ensure they are correct (according to my subjective opinion of course).\n",
    "I also filtered out the sentences that were vague and didn't seem to have a clear stereotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "b579c484-39f1-4fc4-b7a6-9b5fd388778e",
    "outputId": "6222c838-bcc7-4151-b10d-bd6f459a5560"
   },
   "outputs": [],
   "source": [
    "df_stereo_filtered = df_stereo_flat[df_stereo_flat['label_type'] == 'stereotype'].reset_index(drop=True)\n",
    "df_stereo_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c6220940-b89b-4e04-99e6-7993f2553d41",
    "outputId": "603f5ca6-2152-4a47-9775-1833b05adafe"
   },
   "outputs": [],
   "source": [
    "# like this for every 50 interval so 0-50, 50-100, 100-150, 150-200, 200-242\n",
    "df_stereo_filtered.iloc[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "57f1e27f-5bde-4904-86ab-1c62d244330a"
   },
   "outputs": [],
   "source": [
    "# very time consuming but didn't trust key-word matching or sentiment analysis fully (could potentially try them later)\n",
    "stereotype_mapping = {\n",
    "    0: 6,\n",
    "    1: 3,\n",
    "    2: 2,\n",
    "    3: 5,\n",
    "    4: None,  # will filter out all nans later\n",
    "    5: 3,\n",
    "    6: 7,\n",
    "    7: 12,\n",
    "    8: 7,\n",
    "    9: 3,\n",
    "    10: 2,\n",
    "    11: 2,\n",
    "    12: 1,\n",
    "    13: 3,\n",
    "    14: 7,\n",
    "    15: None,\n",
    "    16: 6,\n",
    "    17: 3,\n",
    "    18: 7,\n",
    "    19: 3,\n",
    "    20: 3,\n",
    "    21: 3,\n",
    "    22: None,\n",
    "    23: 7,\n",
    "    24: 1,\n",
    "    25: 8,\n",
    "    26: 12,\n",
    "    27: 11,\n",
    "    28: 3,\n",
    "    29: 5,\n",
    "    30: 7,\n",
    "    31: 4,\n",
    "    32: 7,\n",
    "    33: None,\n",
    "    34: 4,\n",
    "    35: 3,\n",
    "    36: 12,\n",
    "    37: 15,\n",
    "    38: None,\n",
    "    39: 2,\n",
    "    40: 7,\n",
    "    41: 5,\n",
    "    42: 3,\n",
    "    43: None,\n",
    "    44: 7,\n",
    "    45: 5,\n",
    "    46: 4,\n",
    "    47: 7,\n",
    "    48: None,\n",
    "    49: 3,\n",
    "    50: 3,\n",
    "    51: 7,\n",
    "    52: 14,\n",
    "    53: 3,\n",
    "    54: 3,\n",
    "    55: 2,\n",
    "    56: 4,\n",
    "    57: 1,\n",
    "    58: 5,\n",
    "    59: 7,\n",
    "    60: None,\n",
    "    61: 6,\n",
    "    62: 3,\n",
    "    63: 5,\n",
    "    64: 8,\n",
    "    65: 12,\n",
    "    66: 5,\n",
    "    67: 6,\n",
    "    68: 7,\n",
    "    69: 9,\n",
    "    70: 13,\n",
    "    71: None,\n",
    "    72: 5,\n",
    "    73: 12,\n",
    "    74: 15,\n",
    "    75: None,\n",
    "    76: 16,\n",
    "    77: 9,\n",
    "    78: 3,\n",
    "    79: 12,\n",
    "    80: 8,\n",
    "    81: 13,\n",
    "    82: 3,\n",
    "    83: 6,\n",
    "    84: None,\n",
    "    85: 3,\n",
    "    86: 8,\n",
    "    87: None,\n",
    "    88: 9,\n",
    "    89: 3,\n",
    "    90: 3,\n",
    "    91: None,\n",
    "    92: 15,\n",
    "    93: 6,\n",
    "    94: 11,\n",
    "    95: 10,\n",
    "    96: 9,\n",
    "    97: 9,\n",
    "    98: 3,\n",
    "    99: None,\n",
    "    100: None,\n",
    "    101: 1,\n",
    "    102: 10,\n",
    "    103: 15,\n",
    "    104: 12,\n",
    "    105: None,\n",
    "    106: 1,\n",
    "    107: 12,\n",
    "    108: 16,\n",
    "    109: 6,\n",
    "    110: 4,\n",
    "    111: 5,\n",
    "    112: 12,\n",
    "    113: 11,\n",
    "    114: 15,\n",
    "    115: None,\n",
    "    116: 16,\n",
    "    117: 16,\n",
    "    118: 12,\n",
    "    119: 8,\n",
    "    120: 8,\n",
    "    121: 2,\n",
    "    122: 7,\n",
    "    123: None,\n",
    "    124: 15,\n",
    "    125: 11,\n",
    "    126: 6,\n",
    "    127: 1,\n",
    "    128: 15,\n",
    "    129: 14,\n",
    "    130: 12,\n",
    "    131: 3,\n",
    "    132: 13,\n",
    "    133: 9,\n",
    "    134: 8,\n",
    "    135: 8,\n",
    "    136: 1,\n",
    "    137: 13,\n",
    "    138: 6,\n",
    "    139: 11,\n",
    "    140: 3,\n",
    "    141: 9,\n",
    "    142: 15,\n",
    "    143: 9,\n",
    "    144: 9,\n",
    "    145: 7,\n",
    "    146: None,\n",
    "    147: 11,\n",
    "    148: 10,\n",
    "    149: 16,\n",
    "    150: None,\n",
    "    151: 16,\n",
    "    152: 15,\n",
    "    153: 14,\n",
    "    154: 12,\n",
    "    155: 1,\n",
    "    156: None,\n",
    "    157: 3,\n",
    "    158: 12,\n",
    "    159: None,\n",
    "    160: 9,\n",
    "    161: 3,\n",
    "    162: 16,\n",
    "    163: None,\n",
    "    164: 12,\n",
    "    165: 11,\n",
    "    166: 8,\n",
    "    167: None,\n",
    "    168: 16,\n",
    "    169: 3,\n",
    "    170: 8,\n",
    "    171: None,\n",
    "    172: 10,\n",
    "    173: 16,\n",
    "    174: 3,\n",
    "    175: None,\n",
    "    176: 3,\n",
    "    177: None,\n",
    "    178: 12,\n",
    "    179: 12,\n",
    "    180: 14,\n",
    "    181: None,\n",
    "    182: None,\n",
    "    183: 7,\n",
    "    184: None,\n",
    "    185: 8,\n",
    "    186: 10,\n",
    "    187: None,\n",
    "    188: 8,\n",
    "    189: 10,\n",
    "    190: 2,\n",
    "    191: 6,\n",
    "    192: 14,\n",
    "    193: 14,\n",
    "    194: 10,\n",
    "    195: 16,\n",
    "    196: 13,\n",
    "    197: 9,\n",
    "    198: None,\n",
    "    199: None,\n",
    "    200: 14,\n",
    "    201: None,\n",
    "    202: None,\n",
    "    203: 8,\n",
    "    204: 10,\n",
    "    205: 1,\n",
    "    206: None,\n",
    "    207: 8,\n",
    "    208: 3,\n",
    "    209: 12,\n",
    "    210: 6,\n",
    "    211: 16,\n",
    "    212: 12,\n",
    "    213: 7,\n",
    "    214: 8,\n",
    "    215: 14,\n",
    "    216: 10,\n",
    "    217: 10,\n",
    "    218: 12,\n",
    "    219: None,\n",
    "    220: 3,\n",
    "    221: None,\n",
    "    222: 10,\n",
    "    223: 12,\n",
    "    224: 12,\n",
    "    225: 15,\n",
    "    226: 14,\n",
    "    227: 11,\n",
    "    228: 14,\n",
    "    229: 16,\n",
    "    230: 3,\n",
    "    231: 14,\n",
    "    232: 1,\n",
    "    233: 14,\n",
    "    234: 8,\n",
    "    235: 12,\n",
    "    236: None,\n",
    "    237: 11,\n",
    "    238: 3,\n",
    "    239: 8,\n",
    "    240: 1,\n",
    "    241: 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "7649917c-80e7-4620-817a-51b104dd31a3",
    "outputId": "ffca8315-9f5e-4839-ab0f-64ee3406c892"
   },
   "outputs": [],
   "source": [
    "# Apply the mapping to the dataset\n",
    "df_stereo_filtered['stereotype'] = df_stereo_filtered.index.map(stereotype_mapping)\n",
    "df_stereo_filtered = df_stereo_filtered.dropna(subset=['stereotype'])\n",
    "df_stereo_filtered['stereotype'] = df_stereo_filtered['stereotype'].astype(int)\n",
    "df_stereo_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "6aa6f82f-7f3f-42f4-8452-f9168e4f9a96",
    "outputId": "66d23b1b-0a3f-4f92-b2e8-a13e28e45e8f"
   },
   "outputs": [],
   "source": [
    "df_stereo_filtered = df_stereo_filtered.reset_index(drop=True) # reset index due to dropped rows\n",
    "df_stereo_filtered = df_stereo_filtered.drop(columns=['context'])\n",
    "df_stereo_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "2d0e81dd-ccfa-4b61-997c-f2f76fcfc3a1"
   },
   "outputs": [],
   "source": [
    "# Concatenating the two datasets along the rows (axis=0)\n",
    "merged_df = pd.concat([df_stereo_filtered, df_gest_clean], ignore_index=True)\n",
    "merged_df\n",
    "merged_df.to_parquet(\"merged_dataset.parquet\", index=False) #save to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "86cb5929-cbb5-4d2f-85e0-4199b4c36336"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "ca016957-b85f-4e6c-97d7-301aaa0785df"
   },
   "source": [
    "EDA steps:\n",
    "- Stereotype distribution -> ensure merged dataset is balanced\n",
    "- Sentence length distribution and removal of outliers -> helps calibrate prompt size and model input limits\n",
    "- Lexical content per group -> early signal of stereotypical phrasing\n",
    "    - preprocessing + tokenization + word frequency analysis\n",
    "- Initial t-SNE plot -> preview embedding structure before full analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "id": "2c757784-5826-4bbd-b3b5-d9d4b8439f0a"
   },
   "source": [
    "#### Stereotype Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "462749f1-cb0a-44c1-85f4-3cc6056f35e9",
    "outputId": "1f9f9636-ae38-4b8f-bc0a-a8d25ee9792d"
   },
   "outputs": [],
   "source": [
    "counts = merged_df['stereotype'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "b06238b4-0082-4413-9721-6f9005c60a24",
    "outputId": "ce67d626-de81-4020-8fd8-36cb85fa0592"
   },
   "outputs": [],
   "source": [
    "counts = merged_df['stereotype'].value_counts().sort_index()\n",
    "percentages = merged_df['stereotype'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "df_counts = pd.DataFrame({\n",
    "    \"count\": counts,\n",
    "    \"percentage\": percentages\n",
    "})\n",
    "# Mapping stereotype labels and gender groups\n",
    "label_map = {\n",
    "    1: \"Women are emotional and irrational\",\n",
    "    2: \"Women are gentle, kind, and submissive\",\n",
    "    3: \"Women are empathetic and caring\",\n",
    "    4: \"Women are neat and diligent\",\n",
    "    5: \"Women are social\",\n",
    "    6: \"Women are weak\",\n",
    "    7: \"Women are beautiful\",\n",
    "    8: \"Men are tough and rough\",\n",
    "    9: \"Men are self-confident\",\n",
    "    10: \"Men are professional\",\n",
    "    11: \"Men are rational\",\n",
    "    12: \"Men are providers\",\n",
    "    13: \"Men are leaders\",\n",
    "    14: \"Men are childish\",\n",
    "    15: \"Men are sexual\",\n",
    "    16: \"Men are strong\"\n",
    "}\n",
    "df_counts[\"label\"] = df_counts.index.map(label_map)\n",
    "df_counts[\"group\"] = df_counts.index.map(lambda x: \"Women\" if x <= 7 else \"Men\")\n",
    "\n",
    "# Setting colors based on group\n",
    "color_map = {\"Women\": \"lightpink\", \"Men\": \"lightblue\"}\n",
    "colors = df_counts[\"group\"].map(color_map)\n",
    "# Sorting\n",
    "df_counts = df_counts.sort_values(\"count\", ascending=True)\n",
    "colors = colors.loc[df_counts.index]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(df_counts[\"label\"], df_counts[\"count\"], color=colors)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.title(\"Stereotype Category Distribution by Gender\")\n",
    "\n",
    "for bar, pct in zip(bars, df_counts[\"percentage\"]):\n",
    "    plt.text(bar.get_width() + 2, bar.get_y() + bar.get_height()/2, f\"{pct:.1f}%\", va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "e816b088-279a-4951-b182-8ab4565bc881"
   },
   "source": [
    "The distribution of gender stereotypes in the dataset is relatively balanced, with percentages ranging from 5.5 to 7.7, indicating no major outliers and a good representation of all 16 stereotype categories. The most represented stereotype is “Women are empathetic and caring” (7.7%), followed by “Men are tough and rough” (7.1%) and “Women are emotional and irrational” (7.0%). The least represented stereotypes are “Men are childish”, “Women are weak”, and “Women are social”, all around 5.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "id": "9dae4222-0a8e-422d-b504-d543158340c6"
   },
   "source": [
    "#### Sentence length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ce107388-465f-4699-b3cb-98bfcd8f255b",
    "outputId": "3283871c-8439-43c5-d358-9649b6d672c4"
   },
   "outputs": [],
   "source": [
    "# Computes sentence lengths (word count)\n",
    "merged_df[\"length\"] = merged_df[\"sentence\"].apply(lambda x: len(str(x).split()))\n",
    "# Plot histogram for overall sentence lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(merged_df[\"length\"], bins=30, color=\"seagreen\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Sentence Length (words)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Overall Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "5249ede3-8fce-4160-8225-489aa7476dad"
   },
   "source": [
    "Most sentences have around 10 words, with the majority falling under the 6-13 range. A few outliers are evident at both extremes (2 or 30 words).\n",
    "This indicates a fairly well-distributed sentence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c75cb1da-42e7-47bb-880e-acec9e51c231",
    "outputId": "d09fb5c5-1bbc-4ed2-a734-5a00c5c932bb"
   },
   "outputs": [],
   "source": [
    "# Based on my embedding and prompt-based methodology, removing outliers makes sense. Outliers may distort cosine similarity scores, especially during average pooling.\n",
    "# Computing Q1, Q3, and IQR\n",
    "q1 = merged_df[\"length\"].quantile(0.25)\n",
    "q3 = merged_df[\"length\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Defining outlier bounds\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Filtering the dataset\n",
    "filtered_df = merged_df[(merged_df[\"length\"] >= lower_bound) & (merged_df[\"length\"] <= upper_bound)]\n",
    "\n",
    "print(f\"Original size: {merged_df.shape[0]}\")\n",
    "print(f\"Filtered size: {filtered_df.shape[0]}\")\n",
    "print(f\"Removed outliers: {merged_df.shape[0] - filtered_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "id": "8ac1d0ce-9144-4447-bc09-f5cffb51ffec"
   },
   "outputs": [],
   "source": [
    "filtered_df.to_parquet(\"filtered_df.parquet\", index=False) #save to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "bb2d8bbd-0e25-4f20-be64-c27a6aaf0b4d"
   },
   "source": [
    "#### Sentence preprocessing, tokenization & word frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59c5bee3-18f4-4495-9354-eb7294cf84e8",
    "outputId": "5c0913e0-f030-49cc-fb59-57ec5826c52d"
   },
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9adb50b-3a1a-47d6-af76-ed67de47f127",
    "outputId": "2842c15e-90c6-47a0-9710-1654b39d203e"
   },
   "outputs": [],
   "source": [
    "# Defining stopwords with some additions\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "additional_stops = {\"like\", \"could\", \"would\", \"im\", \"get\", \"got\", \"one\", \"also\", \"dont\", \"didnt\", \"even\", \"always\", \"never\"}\n",
    "stop_words.update(additional_stops)\n",
    "\n",
    "# Preprocessing and tokenizing all sentences\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)  # removes punctuation\n",
    "    tokens = word_tokenize(text)\n",
    "    return [t for t in tokens if t not in stop_words]\n",
    "\n",
    "tokens = []\n",
    "for sentence in filtered_df[\"sentence\"]:\n",
    "    tokens.extend(preprocess(sentence))\n",
    "\n",
    "# Counting word frequencies\n",
    "word_counts = Counter(tokens)\n",
    "freq_df = pd.DataFrame(word_counts.items(), columns=[\"word\", \"count\"]).sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Show top and bottom 15\n",
    "print(\"Most frequent words:\\n\", freq_df.head(15))\n",
    "print(\"\\nLeast frequent words:\\n\", freq_df.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c532320f-2416-4f00-baeb-3675ae0620e9",
    "outputId": "0816d5b5-097a-42c4-9f35-a6f1f6fdb6f1"
   },
   "outputs": [],
   "source": [
    "# Now let's see the top 5 words per stereotype category:\n",
    "stereotype_top_words = {}\n",
    "\n",
    "# Looping through each stereotype category\n",
    "for cat in sorted(filtered_df[\"stereotype\"].unique()):\n",
    "    cat_sentences = filtered_df[filtered_df[\"stereotype\"] == cat][\"sentence\"]\n",
    "\n",
    "    tokens = []\n",
    "    for sentence in cat_sentences:\n",
    "        tokens.extend(preprocess(sentence))\n",
    "\n",
    "    word_counts = Counter(tokens)\n",
    "    top_words = word_counts.most_common(5)\n",
    "\n",
    "    stereotype_top_words[cat] = top_words\n",
    "\n",
    "for cat, words in stereotype_top_words.items():\n",
    "    print(f\"Stereotype {cat}: {words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "id": "5102cbbb-5ffc-43c0-9dd5-7819b31b76a5"
   },
   "source": [
    "The top 5 most frequent words in each stereotype category strongly align with the associated stereotype label. For example, Stereotype 3 (“Women are empathetic and caring”) includes care, help, and children, while Stereotype 10 (“Men are professional”) includes work, job and professional. These lexical patterns validate the mappings I made from StereoSet to GEST, confirming that the merged dataset preserves semantic coherence across categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "id": "746f318a-fe7b-4245-8220-c0a99f837132"
   },
   "source": [
    "#### Initial t-SNE plot -> Preview embedding structure before full analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "id": "59565a6d-01d2-4a55-9392-6eb1f796fa48"
   },
   "source": [
    "Sources:\n",
    "- https://huggingface.co/docs/transformers/en/model_doc/gpt2\n",
    "- https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2\n",
    "- https://stackoverflow.com/questions/52849890/how-to-implement-t-sne-in-a-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "id": "e1bf76c8-42e7-4af7-8d95-eb793c5a5025"
   },
   "source": [
    "#### Starting with gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "id": "514ff19a-7d58-4ef6-99b3-210e24b5150e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "id": "beda9edf-0317-45ed-a045-8689289d05da"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "id": "989be2e7-7cea-4199-8581-30b3d88aeb34",
    "outputId": "bfb274f8-e681-4222-e7e2-a4a777bfb2fa"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "id": "yNbXD7_Nz1Ya"
   },
   "outputs": [],
   "source": [
    "# Getting average-pooled sentence embedding from GPT-2\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        embedding = last_hidden_state.mean(dim=1).squeeze()\n",
    "    return embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "234fbb12-07ba-4605-9c45-a2a97062edda",
    "outputId": "d814a64a-00fd-4f4d-c546-1745956fd435"
   },
   "outputs": [],
   "source": [
    "# Extracting embeddings for all sentences\n",
    "embeddings = []\n",
    "for sentence in tqdm(filtered_df[\"sentence\"], desc=\"Extracting GPT-2 embeddings\"):\n",
    "    emb = get_embedding(sentence)\n",
    "    embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "5dfcb98e-8a8a-4c24-a56e-ae1bb38428e5",
    "outputId": "73420471-d9b3-4ecb-af1a-9b0ac7f6bea3"
   },
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings)  # shape = (n_sentences, 768)\n",
    "embeddings_df[\"stereotype\"] = filtered_df[\"stereotype\"].values # added 1 col\n",
    "embeddings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "id": "a8943959-d9c3-4aaa-a089-04017a04b87d"
   },
   "outputs": [],
   "source": [
    "# Applying t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(embeddings_df.iloc[:, :-1]) # select all columns except for stereotype col I added\n",
    "embeddings_df[\"tsne_x\"] = tsne_result[:, 0]\n",
    "embeddings_df[\"tsne_y\"] = tsne_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "id": "c19e6db4-7586-4f99-bc6c-bac0d211fe16",
    "outputId": "4ca4e15b-765f-4108-9c8d-a23cdc754e8a"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cat in sorted(embeddings_df[\"stereotype\"].unique()):\n",
    "    subset = embeddings_df[embeddings_df[\"stereotype\"] == cat]\n",
    "    plt.scatter(subset[\"tsne_x\"], subset[\"tsne_y\"], label=f\"Cat {cat}\", alpha=0.7)\n",
    "plt.title(\"t-SNE of GPT-2 Embeddings\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "id": "7d68c9c9-6964-4404-9ec3-790e9f8428ed"
   },
   "source": [
    "I don't see any clusters forming, I think 16 categories might be too many for a 2D representation so that's why they are not separating clearly. Lets try clustering my gender so from categories 1-7 (female stereotypes) and 8-16 (male stereotypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "id": "68846d03-4549-4bfa-b06c-fe50ce9aace0",
    "outputId": "3797d666-9f97-4901-c75f-7f941987e5a0"
   },
   "outputs": [],
   "source": [
    "embeddings_df[\"gender_group\"] = embeddings_df[\"stereotype\"].apply(lambda x: \"Women\" if x <= 7 else \"Men\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for group in sorted(embeddings_df[\"gender_group\"].unique()):\n",
    "    subset = embeddings_df[embeddings_df[\"gender_group\"] == group]\n",
    "    plt.scatter(subset[\"tsne_x\"], subset[\"tsne_y\"], label=group, alpha=0.7)\n",
    "plt.title(\"t-SNE of GPT-2 Embeddings by Gender Group\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "id": "5ddeca57-4e85-4f9e-9717-268609b9439d"
   },
   "source": [
    "The t-SNE plot shows overlapping male and female stereotype embeddings in GPT-2, suggesting no clear separation at the sentence level. This motivates deeper analysis (e.g., cosine similarity, prompt completions) to uncover more subtle forms of gender bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "id": "16b1e1e2-3b55-4027-b41c-c90eda271fe3"
   },
   "source": [
    "### Now LLaMA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "fecc406368904e14b9c405cb782eb202",
      "49824b2919b740cbbbd50032b58bcdfb",
      "76f5404e603442d595fa5c80b61c9644",
      "8d6ef84c5b584647aeb297d70274660a",
      "9ca515f52c3b483c9d8a3efd58d2f243",
      "8301749523174bd4b7e15a3440e48d47",
      "a877b6b52e9c4a95b20a8a5a4f6f0528",
      "ca5e6b4740dc4dc88fec325dcd8b54ac",
      "f31bd45969fd49f1a8d4c9e0b12fb20e",
      "94c9c5c862f140808ae7a7af7297bebe",
      "7af5098d29d549cda70cf44455e9d1bb",
      "7144fabdf5684f0aa7214dac43d15e6a",
      "275028478bd44baf92b1d00636d111c6",
      "da58ee15992e43b0b7e8347f795220d2",
      "690899ca038246bc9cbc8f567eb79a10",
      "e89bcb9c23d54f38b4c80e9df35abe63",
      "962c9d0305464f2da1b3ba63624765d6",
      "ed2b4ac5948540e6942fd4e408bd1160",
      "8d945c58799f4bdab37b5743d5e623db",
      "d63f47c8efa940979368381e4b9fda40"
     ]
    },
    "id": "6ea6f837-d330-444e-8e01-1469e814113d",
    "outputId": "e4055454-db9d-44a1-d8a8-7a64b164c0dc"
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "#login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521,
     "referenced_widgets": [
      "fd50e39b078147ce9910c64a9fc0d3d9",
      "c32aa0b4e5e64086b49ff0168b05d638",
      "7d9bb750778a4cbb89bc12270d8648c7",
      "c1a35a0ae2de413bbfb2440fb672fdc6",
      "0c7b05528154447d8e5c11323d34132e",
      "4a5195f05a704e9aad0f3babb060628c",
      "5e7b8bf954bb4ea99e8c94ff66563ba8",
      "a5c1583c0aeb4519ac6b0371abe8ac07",
      "58707d42c1ea401da6e22d386a3d006c",
      "6e696a431c874a8b8f474a1230ee5b42",
      "df1c7d3a52574a82a3c1a39484ed67c6"
     ]
    },
    "id": "4d37c6de-1dc0-4483-ae3f-eb32fd1a0b17",
    "outputId": "1ecd385d-c453-429a-b893-ad1bf83e9dcb"
   },
   "outputs": [],
   "source": [
    "# model_id = \"meta-llama/Llama-2-7b-chat-hf\" -> commenting this out cause i'm having trouble uploading it to github\n",
    "\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"            # automatically sends model to GPU if available\n",
    ")\n",
    "llama_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Bs_BuzYyJQc",
    "outputId": "8faa2ec6-1437-4642-efa3-d151d75274a0"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "llama_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b80ec187-2197-42d6-b85f-e7c2dfceb22d",
    "outputId": "5d9dab84-45ba-4937-91af-a2259d950291"
   },
   "outputs": [],
   "source": [
    "# # Getting average-pooled sentence embedding from LlaMA-2 -> similar struct to gpt-2 but the hidden layers are called differently\n",
    "def get_llama2_embedding(text, model, tokenizer, device):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states[-1]  # last layer\n",
    "        embedding = hidden_states.mean(dim=1).squeeze()\n",
    "    return embedding.cpu().numpy()\n",
    "\n",
    "# Extracting embeddings for all sentences\n",
    "llama_embeddings = []\n",
    "for sentence in tqdm(filtered_df[\"sentence\"], desc=\"Extracting LLaMA embeddings\"):\n",
    "    emb = get_llama2_embedding(sentence, llama_model, llama_tokenizer, device)\n",
    "    llama_embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc849463-e283-456a-860f-a8e59e357337",
    "outputId": "c5f2ad99-aa36-4cb1-f94b-dbf0116283b8"
   },
   "outputs": [],
   "source": [
    "embeddings_llama = pd.DataFrame(llama_embeddings)  # shape\n",
    "embeddings_llama[\"stereotype\"] = filtered_df[\"stereotype\"].values # added 1 col\n",
    "embeddings_llama.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "id": "b3dcc6c2-56d0-4eb8-b693-a8f50b828a2e"
   },
   "outputs": [],
   "source": [
    "# Applying t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(embeddings_llama.iloc[:, :-1]) # select all columns except for stereotype col I added\n",
    "embeddings_llama[\"tsne_x\"] = tsne_result[:, 0]\n",
    "embeddings_llama[\"tsne_y\"] = tsne_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "df11a043-4a8b-416f-8f67-7d4c592c0e2f",
    "outputId": "29eb002c-969d-44e3-ae8f-a9c629c0afd3"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cat in sorted(embeddings_llama[\"stereotype\"].unique()):\n",
    "    subset = embeddings_llama[embeddings_llama[\"stereotype\"] == cat]\n",
    "    plt.scatter(subset[\"tsne_x\"], subset[\"tsne_y\"], label=f\"Cat {cat}\", alpha=0.7)\n",
    "plt.title(\"t-SNE of LlaMA Embeddings\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Compared to GPT-2, the t-SNE plots for LLaMA-2 embeddings show a bit more structure. For example, there’s a noticeable cluster of points from Category 16 (e.g., “Men are strong”) between -20 and 0 on the t-SNE 1 axis. Right next to it, there's also a small grouping for Category 14 (“Men are childish”), which might suggest some overlap in how these stereotypes are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "c55e6dfa-5769-49d8-9721-b4d1c3cb43b2",
    "outputId": "59b0856d-f409-4b49-e68d-1e5d949517e6"
   },
   "outputs": [],
   "source": [
    "embeddings_llama[\"gender_group\"] = embeddings_llama[\"stereotype\"].apply(lambda x: \"Women\" if x <= 7 else \"Men\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for group in sorted(embeddings_llama[\"gender_group\"].unique()):\n",
    "    subset = embeddings_llama[embeddings_llama[\"gender_group\"] == group]\n",
    "    plt.scatter(subset[\"tsne_x\"], subset[\"tsne_y\"], label=group, alpha=0.7)\n",
    "plt.title(\"t-SNE of LLaMA-2 Embeddings by Gender Group\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "In this plot, the orange dots (Women) seem to concentrate more around the middle-left of the plot (roughly t-SNE 1 from 0 to 20 and t-SNE 2 from -20 to -40), while some blue areas (Men) show up on the far right (t-SNE 1 from 40 to 60). It’s not a perfect separation, but it's clearer than what I observed with GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "This suggests that LLaMA-2 might already be encoding some gender-related differences in its embeddings. So even before doing anything more complex like cosine similarity or prompt completions, the embeddings already hint at underlying biases — which makes a stronger case for looking deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### Conclusions from EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "##### - Stereotype Category Distribution:\n",
    "    - All 16 stereotype categories are well represented in the dataset, ranging from 206 to 290 instances each.\n",
    "    - No major imbalances were found, which ensures fairness and robustness for downstream analysis.\n",
    "##### - Sentence Length Distribution:\n",
    "    - Most sentences are around 5-15 words long.\n",
    "    - A few outliers (very short or very long sentences) were identified and removed (~110 sentences) to prevent noise in embedding generation.\n",
    "##### - Word Frequency Analysis:\n",
    "    - Words like care, home, and felt were more common in Women stereotypes, while work, money, and team were more frequent in Men stereotypes.\n",
    "    - Per-category analysis further confirmed that the most frequent words aligned well with the stereotype labels, validating the mapping from StereoSet to GEST.\n",
    "##### - t-SNE Visualization – GPT-2 vs LLaMA-2 Embeddings:\n",
    "    - GPT-2 embeddings showed little structure; all stereotype categories and gender groups were highly intermixed.\n",
    "    - LLaMA-2 embeddings revealed more noticeable clusters. This clustering suggests that LLaMA-2 is already encoding stereotypical signals in its internal representation space — even before any generation or classification step.\n",
    "##### - Justification of research question:\n",
    "    - These EDA results provide early evidence that large language models like LLaMA-2 may internalize gender biases at the embedding level.\n",
    "    - The differences between GPT-2 and LLaMA-2 also highlight the potential impact of instruction tuning on how stereotypes are encoded.\n",
    "    - This strongly justifies a deeper investigation into how and where gender stereotypes are represented — comparing both prompt-based outputs and internal embeddings — as outlined in the rest of the study."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:neuralnetworks]",
   "language": "python",
   "name": "conda-env-neuralnetworks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
