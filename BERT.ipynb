{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TLWVKHITCXhS"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline, set_seed\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdyxM2D7CrnS",
        "outputId": "f32d723d-3e2e-451f-eb69-06bfe146660f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/LLM_thesis/filtered_df.parquet'\n",
        "filtered_df = pd.read_parquet(file_path)"
      ],
      "metadata": {
        "id": "qGkRK9LLCuG_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a balanced subset for embedding analysis"
      ],
      "metadata": {
        "id": "qSI9Q0lDEZzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes a subset of 5 sentences that contain gendered terms per category to ensure a balanced representation\n",
        "balanced_sample = []\n",
        "\n",
        "for cat in sorted(filtered_df[\"stereotype\"].unique()):\n",
        "    group = filtered_df[filtered_df[\"stereotype\"] == cat]\n",
        "\n",
        "    # Filters for gendered terms\n",
        "    gendered = group[group[\"sentence\"].str.lower().str.contains(r\"\\b(he|she|man|woman|boy|girl|his|her|men|women)\\b\")]\n",
        "\n",
        "    if len(gendered) >= 5:\n",
        "        sample = gendered.sample(n=5, random_state=42)\n",
        "        balanced_sample.append(sample)\n",
        "    else:\n",
        "        print(f\"⚠️ Not enough gendered examples in category {cat}: only {len(gendered)} found\")\n",
        "\n",
        "final_subset_df = pd.concat(balanced_sample).reset_index(drop=True)\n",
        "print(f\"Final balanced subset: {len(final_subset_df)} sentences\")\n",
        "final_subset_df.to_parquet(\"subset_df.parquet\", index=False) # save to parquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPMeUb5xCvlU",
        "outputId": "89b928e1-2533-4379-d5ae-6efe0ba409e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final balanced subset: 80 sentences\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-39748838d653>:8: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  gendered = group[group[\"sentence\"].str.lower().str.contains(r\"\\b(he|she|man|woman|boy|girl|his|her|men|women)\\b\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving extraction logic (first tying dependency-based adjectives/nouns, and if there are none then we have the proximity fallback)"
      ],
      "metadata": {
        "id": "2fzAXWnRV8C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_gender_and_closest_token(text):\n",
        "    doc = nlp(text)\n",
        "    gender_terms = {\"he\", \"she\", \"his\", \"her\", \"man\", \"woman\", \"boy\", \"girl\", \"women\", \"men\"}\n",
        "    gender_idxs = [i for i, token in enumerate(doc) if token.text.lower() in gender_terms]\n",
        "\n",
        "    if not gender_idxs:\n",
        "        return pd.Series([None, None])\n",
        "\n",
        "    gender_token = doc[gender_idxs[0]]\n",
        "    gender_term = gender_token.text\n",
        "\n",
        "    # First try: dependency-based related adjectives/nouns\n",
        "    related = [child.text for child in gender_token.children\n",
        "               if child.pos_ in {\"ADJ\", \"NOUN\"} and not child.is_stop]\n",
        "\n",
        "    if related:\n",
        "        return pd.Series([gender_term, related[0]])\n",
        "\n",
        "    # Fallback: distance-based\n",
        "    uninformative_words = {\"lot\", \"lots\", \"many\", \"thing\", \"stuff\", \"one\", \"someone\"}\n",
        "    candidates = [(i, token.text) for i, token in enumerate(doc)\n",
        "                  if token.pos_ in {\"NOUN\", \"ADJ\"}\n",
        "                  and token.text.lower() not in gender_terms\n",
        "                  and not token.is_stop\n",
        "                  and token.text.lower() not in uninformative_words]\n",
        "\n",
        "    if not candidates:\n",
        "        return pd.Series([gender_term, None])\n",
        "\n",
        "    closest = min(candidates, key=lambda x: abs(x[0] - gender_token.i))\n",
        "    return pd.Series([gender_term, closest[1]])"
      ],
      "metadata": {
        "id": "TViIPRQIOTk8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_subset_df[[\"pronoun\", \"relevant_token\"]] = final_subset_df[\"sentence\"].apply(extract_gender_and_closest_token)"
      ],
      "metadata": {
        "id": "QJCflTm5Gxla"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Switching baseline model to BERT\n",
        "- I am switching the baseline model from GPT-2 to BERT because BERT supports masked completions, making it easier to design and evaluate prompt-based sentence completions in a structured way. This allows for a more direct comparison with LLaMA-2, which will also be used for completion-based prompts. To quantify bias, masking the pronoun and prompting the model to complete the sentence provides a clearer and more interpretable signal of gender associations in the model's outputs."
      ],
      "metadata": {
        "id": "JM7YULjOEctr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources:\n",
        "- https://huggingface.co/docs/transformers/model_doc/bert\n",
        "- https://bert-vs-gpt2.dbvis.de/"
      ],
      "metadata": {
        "id": "-ORmlQVWE9mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f6Zc50rE8uc",
        "outputId": "965ee4fc-259b-4347-a78f-bb29e9d68ba6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing cosine similarity at the token level for gendered term & adj/noun for BERT"
      ],
      "metadata": {
        "id": "BqQz02NMHVKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same function as gpt2\n",
        "def get_bert_token_embedding(text, target_token):\n",
        "    if not target_token:\n",
        "        return None\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze())\n",
        "\n",
        "    match_indices = [i for i, tok in enumerate(tokens) if target_token.lower() in tok.lower()]\n",
        "    if not match_indices:\n",
        "        return None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        last_hidden_state = outputs.last_hidden_state.squeeze(0)\n",
        "\n",
        "    return last_hidden_state[match_indices[0]].cpu().numpy()\n"
      ],
      "metadata": {
        "id": "tpVwFdrdHXYb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute cosine similarity\n",
        "def compute_cosine(row):\n",
        "    sentence = row[\"sentence\"]\n",
        "    pronoun = row[\"pronoun\"]\n",
        "    token = row[\"relevant_token\"]\n",
        "\n",
        "    emb_pronoun = get_bert_token_embedding(sentence, pronoun)\n",
        "    emb_token = get_bert_token_embedding(sentence, token)\n",
        "    if emb_pronoun is None or emb_token is None:\n",
        "        return 0.0\n",
        "\n",
        "    return cosine_similarity([emb_pronoun], [emb_token])[0][0]"
      ],
      "metadata": {
        "id": "NcSu7QE4H7UU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_subset_df[\"cosine_similarity\"] = final_subset_df.apply(compute_cosine, axis=1)"
      ],
      "metadata": {
        "id": "-9RRVzEwH9YD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_subset_df.head(50)"
      ],
      "metadata": {
        "id": "TG6drS25SOZG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(final_subset_df['cosine_similarity'].dropna(), bins=30)\n",
        "plt.title(\"Distribution of Cosine Similarities\")\n",
        "plt.xlabel(\"Cosine Similarity\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "iz045dP_IXnz",
        "outputId": "827af660-ab56-4d0c-85de-e37ea73046d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BERT sees the words before and after a word when creating its embedding. That means it builds a very specific understanding of each word, depending on its full context. This leads to more variation in similarity scores. Therefore BERT's similarity scores are actually more discriminative.\n",
        "\n",
        "- GPT-2 only sees the words that come before a word. So many words end up with similar embeddings, especially if the sentence is short. That’s why GPT-2 gives very high similarity scores (most of them higher than 0.8)."
      ],
      "metadata": {
        "id": "BZE9jEIjJDPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each stereotype category(16) show the pronoun and relevant token with highest and lowest cosine similarities\n",
        "# Groups data by stereotype category\n",
        "grouped = final_subset_df.groupby(\"stereotype\")\n",
        "\n",
        "# Iterates through each stereotype category\n",
        "for stereotype, group_df in grouped:\n",
        "    # Filters out rows where relevant_token is None for lowest similarity\n",
        "    valid_rows = group_df[group_df[\"relevant_token\"].notna()]\n",
        "    # Finds the highest and lowest cosine similarity for each category\n",
        "    highest_similarity_row = valid_rows.loc[valid_rows['cosine_similarity'].idxmax()]\n",
        "    lowest_similarity_row = valid_rows.loc[valid_rows['cosine_similarity'].idxmin()]\n",
        "\n",
        "    print(f\"Stereotype: {stereotype}\")\n",
        "    print(f\"  Highest Cosine Similarity:\")\n",
        "    print(f\"    Pronoun: {highest_similarity_row['pronoun']}\")\n",
        "    print(f\"    Relevant Token: {highest_similarity_row['relevant_token']}\")\n",
        "    print(f\"    Cosine Similarity: {highest_similarity_row['cosine_similarity']:.2f}\")\n",
        "    print(f\"  Lowest Cosine Similarity:\")\n",
        "    print(f\"    Pronoun: {lowest_similarity_row['pronoun']}\")\n",
        "    print(f\"    Relevant Token: {lowest_similarity_row['relevant_token']}\")\n",
        "    print(f\"    Cosine Similarity: {lowest_similarity_row['cosine_similarity']:.2f}\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLtMJ7qiIcjC",
        "outputId": "7bb119f4-4a3d-43c0-e3cb-4505d868b800"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stereotype: 1\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: women\n",
            "    Relevant Token: appearances\n",
            "    Cosine Similarity: 0.51\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: fights\n",
            "    Cosine Similarity: 0.07\n",
            "--------------------\n",
            "Stereotype: 2\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: he\n",
            "    Relevant Token: rude\n",
            "    Cosine Similarity: 0.46\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: housewife\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 3\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: patient\n",
            "    Cosine Similarity: 0.32\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: sons\n",
            "    Cosine Similarity: 0.10\n",
            "--------------------\n",
            "Stereotype: 4\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: she\n",
            "    Relevant Token: neighbour\n",
            "    Cosine Similarity: 0.58\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: slippers\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 5\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: he\n",
            "    Relevant Token: rude\n",
            "    Cosine Similarity: 0.51\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: bossy\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 6\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: women\n",
            "    Relevant Token: football\n",
            "    Cosine Similarity: 0.47\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: bugs\n",
            "    Cosine Similarity: 0.22\n",
            "--------------------\n",
            "Stereotype: 7\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: she\n",
            "    Relevant Token: skirt\n",
            "    Cosine Similarity: 0.35\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: sun\n",
            "    Cosine Similarity: 0.15\n",
            "--------------------\n",
            "Stereotype: 8\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: her\n",
            "    Relevant Token: apartment\n",
            "    Cosine Similarity: 0.55\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: Women\n",
            "    Relevant Token: cars\n",
            "    Cosine Similarity: 0.31\n",
            "--------------------\n",
            "Stereotype: 9\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: he\n",
            "    Relevant Token: mirror\n",
            "    Cosine Similarity: 0.51\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: habit\n",
            "    Cosine Similarity: 0.27\n",
            "--------------------\n",
            "Stereotype: 10\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: men\n",
            "    Relevant Token: polite\n",
            "    Cosine Similarity: 0.53\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: good\n",
            "    Cosine Similarity: 0.24\n",
            "--------------------\n",
            "Stereotype: 11\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: his\n",
            "    Relevant Token: math\n",
            "    Cosine Similarity: 0.66\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: Men\n",
            "    Relevant Token: stubborn\n",
            "    Cosine Similarity: 0.21\n",
            "--------------------\n",
            "Stereotype: 12\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: man\n",
            "    Relevant Token: carpenter\n",
            "    Cosine Similarity: 0.58\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: studious\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 13\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: men\n",
            "    Relevant Token: powerful\n",
            "    Cosine Similarity: 0.74\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: she\n",
            "    Relevant Token: bossy\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 14\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: he\n",
            "    Relevant Token: friend\n",
            "    Cosine Similarity: 0.63\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: life\n",
            "    Cosine Similarity: 0.22\n",
            "--------------------\n",
            "Stereotype: 15\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: women\n",
            "    Relevant Token: attractive\n",
            "    Cosine Similarity: 0.76\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: store\n",
            "    Cosine Similarity: 0.13\n",
            "--------------------\n",
            "Stereotype: 16\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: women\n",
            "    Relevant Token: elderly\n",
            "    Cosine Similarity: 0.80\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: man\n",
            "    Relevant Token: old\n",
            "    Cosine Similarity: 0.05\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary of findings\n",
        "My analysis of pronoun–token cosine similarities using BERT embeddings reveals clear patterns in how gender stereotypes are encoded across 16 stereotype categories.\n",
        "- Several associations are clearly aligned with common gender stereotypes. For instance, in (3) Women are empathetic and caring, she & patient (0.32) reflects expected traits, while in (7) Women are beautiful, she & skirt (0.35) aligns with appearance-based stereotypes. Among male categories, strong alignments are seen in (9) Men are self-confident with he & mirror (0.51), (10) Men are professional with men & polite (0.53), (11) Men are rational with his & math (0.66), (12) Men are providers with man & carpenter (0.58), (13) Men are leaders with men & powerful (0.74), (15) Men are sexual with women & attractive (0.76), and (14) Men are childish with he & friend (0.63).\n",
        "\n",
        "- Other associations are more ambiguous, such as (1) Women are emotional and irrational where women & appearances (0.51) may only loosely reflect the stereotype. Similarly, (5) Women are social with he & rude (0.51), and (8) Men are tough and rough with he & authority (0.42) and her & apartment (0.55) are difficult to interpret. A surprising case appears in (16) Men are strong, where women & elderly (0.8) scores highest, but lacks clear stereotypical meaning.\n",
        "\n",
        "- Finally, a few associations are anti-stereotypical, such as (2) Women are gentle, kind, and submissive with she & housewife (0.00), (6) Women are weak with women & football (0.47) and she & bugs (0.22), and and (4) Women are neat and diligent where her & greasy (0.48) does not reflect neatness. Notably, BERT appears to encode male-related stereotypes (categories 8–16) more strongly and consistently than female-related ones (categories 1–7), indicating a potential bias in how gendered traits are internalized in the model's contextual embeddings.\n",
        "\n"
      ],
      "metadata": {
        "id": "I5kWZNd4YLNc"
      }
    }
  ]
}