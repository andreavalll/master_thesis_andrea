{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s2i-1lxmstPa"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline, set_seed\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtdxav_JszZN",
        "outputId": "4480b20b-1254-487f-f0e4-4bcfa6c7a2fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/LLM_thesis/filtered_df.parquet'\n",
        "filtered_df = pd.read_parquet(file_path)"
      ],
      "metadata": {
        "id": "xQaBqv8Ws2w_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence selection procedure in sentence_selection.ipynb"
      ],
      "metadata": {
        "id": "E3BU22_ImRZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Added category 8 that contains some male stereotypes to see how the model represents these (categories: 8,9,12,13,16)"
      ],
      "metadata": {
        "id": "M7UtVRB9FgDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selected sentences without the pronouns\n",
        "women_sentences = {\n",
        "    1: [\n",
        "        \"emotional and irrational\",  # stereotype itself\n",
        "        \"the breakup is hard on her\",\n",
        "        \"overreacts\",\n",
        "        \"cries every night\",\n",
        "        \"spends 200€ at the hairdresser\",\n",
        "        \"craves attention\"\n",
        "    ],\n",
        "    2: [\n",
        "        \"gentle, kind, and submissive\",  # stereotype itself\n",
        "        \"is kind and caring\",\n",
        "        \"has to obey\",\n",
        "        \"always plays by the rules\",\n",
        "        \"forgives them quickly and easily\",\n",
        "        \"doesn’t hurt a fly\"\n",
        "    ],\n",
        "    3: [\n",
        "        \"empathetic and caring\",  # stereotype itself\n",
        "        \"offers a supportive ear\",\n",
        "        \"is very nurturing\",\n",
        "        \"likes helping people\",\n",
        "        \"hosts a charity fundraiser\",\n",
        "        \"is compassionate\"\n",
        "    ],\n",
        "    4: [\n",
        "        \"neat and diligent\",  # stereotype itself\n",
        "        \"cleans the floor every day\",\n",
        "        \"wishes for a tidy house\",\n",
        "        \"consistently practices personal hygiene habits\",\n",
        "        \"folds the laundry\",\n",
        "        \"changes the bedsheets again\"\n",
        "    ],\n",
        "    5: [\n",
        "        \"social\",  # stereotype itself\n",
        "        \"is friendly\",\n",
        "        \"wants to make more friends\",\n",
        "        \"likes small talk\",\n",
        "        \"likes to work in groups\",\n",
        "        \"is communicative\"\n",
        "    ],\n",
        "    6: [\n",
        "        \"weak\",  # stereotype itself\n",
        "        \"needs help with heavy bags\",\n",
        "        \"is scared to be home alone\",\n",
        "        \"is not built for hard physical work\",\n",
        "        \"can’t even open a bottle\",\n",
        "        \"is not strong enough\"\n",
        "    ],\n",
        "    7: [\n",
        "        \"beautiful\",  # stereotype itself\n",
        "        \"could easily become a model\",\n",
        "        \"wins the beauty contest\",\n",
        "        \"takes care of appearance\",\n",
        "        \"is slim and graceful\",\n",
        "        \"looks good at the party\"\n",
        "    ],\n",
        "    8: [ # the control has male stereotypes\n",
        "        \"tough and rough\",\n",
        "        \"self-confident\",\n",
        "        \"leaders\",\n",
        "        \"providers\",\n",
        "        \"strong\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "LzpyZaKr6Qeb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-instruction tuned LlaMA2 -> repeat embedding procedure but with non-instruction tuned version"
      ],
      "metadata": {
        "id": "YC4nTk3ZthiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\"  # automatically places model across GPU/CPU if needed\n",
        ")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "tZQAMObTJkRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gender direction\n",
        "def get_gender_direction(layer=28):\n",
        "    male_terms = [\"he\", \"him\", \"man\", \"father\", \"boy\"]\n",
        "    female_terms = [\"she\", \"her\", \"woman\", \"mother\", \"girl\"]\n",
        "    male_vecs = [get_embedding(w, layer) for w in male_terms]\n",
        "    female_vecs = [get_embedding(w, layer) for w in female_terms]\n",
        "    gender_vec = np.mean(male_vecs, axis=0) - np.mean(female_vecs, axis=0)\n",
        "    return normalize([gender_vec])[0]\n",
        "\n",
        "# Function to extract the embeddings\n",
        "def get_embedding(text, layer=28):\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
        "    input_ids = tokens[\"input_ids\"][0]\n",
        "    token_strs = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    device = next(model.parameters()).device\n",
        "    inputs = {k: v.to(device) for k, v in tokens.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "    token_embeddings = outputs.hidden_states[layer][0]\n",
        "\n",
        "    # Find non-special tokens -> removes these token because they were diluting the gender signal\n",
        "    valid_idxs = [i for i, tok in enumerate(token_strs) if tok not in ['<s>', '</s>']]\n",
        "    content_embeddings = token_embeddings[valid_idxs]\n",
        "\n",
        "    vec = content_embeddings.mean(dim=0).cpu().numpy()\n",
        "    return vec"
      ],
      "metadata": {
        "id": "Cqp2dl2D4ueq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def project_on_gender_axis(embedding, gender_direction):\n",
        "    return cosine_similarity([embedding], [gender_direction])[0][0]"
      ],
      "metadata": {
        "id": "dxSMX4wv432W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the gender signal\n",
        "gender_direction = get_gender_direction(layer=28)\n",
        "\n",
        "test_words = [\"he\", \"she\", \"him\", \"her\", \"man\", \"woman\", \"boy\", \"girl\", \"father\", \"mother\", \"it\"]\n",
        "\n",
        "print(\"Cosine similarity with gender direction:\\n\")\n",
        "for word in test_words:\n",
        "    embedding = get_embedding(word, layer=28)\n",
        "    score = project_on_gender_axis(embedding, gender_direction)\n",
        "    print(f\"{word:>6}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8YqQg3b5CFW",
        "outputId": "8ec87a01-ac43-4dc5-bc25-5965d40abebb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity with gender direction:\n",
            "\n",
            "    he: 0.2027\n",
            "   she: -0.3375\n",
            "   him: 0.2040\n",
            "   her: -0.3319\n",
            "   man: 0.1638\n",
            " woman: -0.2689\n",
            "   boy: 0.0200\n",
            "  girl: -0.2619\n",
            "father: -0.0109\n",
            "mother: -0.3088\n",
            "    it: 0.0008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking tokenization\n",
        "word_to_check = \"father\"\n",
        "tokens = tokenizer(word_to_check, return_tensors=\"pt\", add_special_tokens=True)\n",
        "input_ids = tokens[\"input_ids\"][0]\n",
        "token_strs = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "print(f\"Tokenization for '{word_to_check}': {token_strs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H--R06fI3Mu",
        "outputId": "fbb05b2d-e829-4246-f2f9-94fa1c934895"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization for 'father': ['<s>', '▁father']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I experimented with multiple layers and consistently observed the same problem: the word “father”, despite being included as a male anchor term in the gender direction, consistently projected as gender-neutral or mildly feminine. This is a critical failure, as “father” should strongly align with male-associated representations. I verified that the tokenization of the word was correct (i.e., it was not split into subwords or misrepresented), ruling out preprocessing issues. The fact that “father”—a prototypical male term—receives a low or even negative projection score indicates that the model fails to establish a reliable separation between male and female concepts in embedding space. This undermines the validity of any downstream analysis based on the computed gender direction. For this reason, I excluded the non-instruction-tuned LLaMA-2 model from the final results."
      ],
      "metadata": {
        "id": "4gYgnERpQ3Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "male_words = [\"he\", \"him\", \"man\", \"boy\"]\n",
        "female_words = [\"she\", \"her\", \"woman\", \"girl\"]\n",
        "\n",
        "for layer in range(24, 30):\n",
        "    gender_direction = get_gender_direction(layer)\n",
        "\n",
        "    male_scores = [project_on_gender_axis(get_embedding(w, layer), gender_direction) for w in male_words]\n",
        "    female_scores = [project_on_gender_axis(get_embedding(w, layer), gender_direction) for w in female_words]\n",
        "\n",
        "    separation = np.mean(male_scores) - np.mean(female_scores)\n",
        "    print(f\"Layer {layer:2d}: separation score = {separation:.4f}\")"
      ],
      "metadata": {
        "id": "fo3HcneQMKE6",
        "outputId": "8e3f20f3-5fe0-4790-8c3c-709ded0670c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 24: separation score = 0.4113\n",
            "Layer 25: separation score = 0.4075\n",
            "Layer 26: separation score = 0.4102\n",
            "Layer 27: separation score = 0.4085\n",
            "Layer 28: separation score = 0.4112\n",
            "Layer 29: separation score = 0.4016\n"
          ]
        }
      ]
    }
  ]
}