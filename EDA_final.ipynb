{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "id": "6c099b7a-f2a0-443e-b942-5d6ba1445218"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "25"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "26"
   },
   "source": [
    "EDA steps:\n",
    "- Stereotype distribution -> ensure merged dataset is balanced\n",
    "- Sentence length distribution and removal of outliers -> helps calibrate prompt size and model input limits\n",
    "- Lexical content per group -> early signal of stereotypical phrasing\n",
    "    - preprocessing + tokenization + word frequency analysis\n",
    "- Initial t-SNE plot -> preview embedding structure before full analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCbqHkGqJXoh",
    "outputId": "dac5f49c-7104-40eb-8ace-b526209958f5"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "7993859b-e3f9-49a0-a034-f7e3ff812db3"
   },
   "outputs": [],
   "source": [
    "# Data Preparation and Creation of merged dataset in preprocessing.ipynb file\n",
    "file_path = '/content/drive/MyDrive/LLM_thesis/merged_dataset.parquet'\n",
    "merged_df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "27"
   },
   "source": [
    "#### Stereotype Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "28",
    "outputId": "b7eef8ff-f739-40aa-d7a0-970ee2a48bee"
   },
   "outputs": [],
   "source": [
    "counts = merged_df['stereotype'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "29",
    "outputId": "ac20c6a3-c665-4d3d-b904-b8ff79525808"
   },
   "outputs": [],
   "source": [
    "counts = merged_df['stereotype'].value_counts().sort_index()\n",
    "percentages = merged_df['stereotype'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "df_counts = pd.DataFrame({\n",
    "    \"count\": counts,\n",
    "    \"percentage\": percentages\n",
    "})\n",
    "# Mapping stereotype labels and gender groups\n",
    "label_map = {\n",
    "    1: \"Women are emotional and irrational\",\n",
    "    2: \"Women are gentle, kind, and submissive\",\n",
    "    3: \"Women are empathetic and caring\",\n",
    "    4: \"Women are neat and diligent\",\n",
    "    5: \"Women are social\",\n",
    "    6: \"Women are weak\",\n",
    "    7: \"Women are beautiful\",\n",
    "    8: \"Men are tough and rough\",\n",
    "    9: \"Men are self-confident\",\n",
    "    10: \"Men are professional\",\n",
    "    11: \"Men are rational\",\n",
    "    12: \"Men are providers\",\n",
    "    13: \"Men are leaders\",\n",
    "    14: \"Men are childish\",\n",
    "    15: \"Men are sexual\",\n",
    "    16: \"Men are strong\"\n",
    "}\n",
    "df_counts[\"label\"] = df_counts.index.map(label_map)\n",
    "df_counts[\"group\"] = df_counts.index.map(lambda x: \"Women\" if x <= 7 else \"Men\")\n",
    "\n",
    "# Setting colors based on group\n",
    "color_map = {\"Women\": \"lightpink\", \"Men\": \"lightblue\"}\n",
    "colors = df_counts[\"group\"].map(color_map)\n",
    "# Sorting\n",
    "df_counts = df_counts.sort_values(\"count\", ascending=True)\n",
    "colors = colors.loc[df_counts.index]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(df_counts[\"label\"], df_counts[\"count\"], color=colors)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.title(\"Stereotype Category Distribution by Gender\")\n",
    "\n",
    "for bar, pct in zip(bars, df_counts[\"percentage\"]):\n",
    "    plt.text(bar.get_width() + 2, bar.get_y() + bar.get_height()/2, f\"{pct:.1f}%\", va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "30"
   },
   "source": [
    "The distribution of gender stereotypes in the dataset is relatively balanced, with percentages ranging from 5.5 to 7.7, indicating no major outliers and a good representation of all 16 stereotype categories. The most represented stereotype is “Women are empathetic and caring” (7.7%), followed by “Men are tough and rough” (7.1%) and “Women are emotional and irrational” (7.0%). The least represented stereotypes are “Men are childish”, “Women are weak”, and “Women are social”, all around 5.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "31"
   },
   "source": [
    "#### Sentence length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "32",
    "outputId": "ac3e3df5-0f19-480a-dbac-c1f7e3565aa9"
   },
   "outputs": [],
   "source": [
    "# Computes sentence lengths (word count)\n",
    "merged_df[\"length\"] = merged_df[\"sentence\"].apply(lambda x: len(str(x).split()))\n",
    "# Plot histogram for overall sentence lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(merged_df[\"length\"], bins=30, color=\"seagreen\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Sentence Length (words)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Overall Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "33"
   },
   "source": [
    "Most sentences have around 10 words, with the majority falling under the 6-13 range. A few outliers are evident at both extremes (2 or 30 words).\n",
    "This indicates a fairly well-distributed sentence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34",
    "outputId": "37ff39d8-ad5e-47ca-d59a-0343fed3a7fa"
   },
   "outputs": [],
   "source": [
    "# Based on my embedding and prompt-based methodology, removing outliers makes sense. Outliers may distort cosine similarity scores, especially during average pooling.\n",
    "# Computing Q1, Q3, and IQR\n",
    "q1 = merged_df[\"length\"].quantile(0.25)\n",
    "q3 = merged_df[\"length\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Defining outlier bounds\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Filtering the dataset\n",
    "filtered_df = merged_df[(merged_df[\"length\"] >= lower_bound) & (merged_df[\"length\"] <= upper_bound)]\n",
    "\n",
    "print(f\"Original size: {merged_df.shape[0]}\")\n",
    "print(f\"Filtered size: {filtered_df.shape[0]}\")\n",
    "print(f\"Removed outliers: {merged_df.shape[0] - filtered_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "35"
   },
   "outputs": [],
   "source": [
    "filtered_df.to_parquet(\"filtered_df.parquet\", index=False) #save to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "36"
   },
   "source": [
    "#### Sentence preprocessing, tokenization & word frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38",
    "outputId": "2842c15e-90c6-47a0-9710-1654b39d203e"
   },
   "outputs": [],
   "source": [
    "# Defining stopwords with some additions\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "additional_stops = {\"like\", \"could\", \"would\", \"im\", \"get\", \"got\", \"one\", \"also\", \"dont\", \"didnt\", \"even\", \"always\", \"never\"}\n",
    "stop_words.update(additional_stops)\n",
    "\n",
    "# Preprocessing and tokenizing all sentences\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)  # removes punctuation\n",
    "    tokens = word_tokenize(text)\n",
    "    return [t for t in tokens if t not in stop_words]\n",
    "\n",
    "tokens = []\n",
    "for sentence in filtered_df[\"sentence\"]:\n",
    "    tokens.extend(preprocess(sentence))\n",
    "\n",
    "# Counting word frequencies\n",
    "word_counts = Counter(tokens)\n",
    "freq_df = pd.DataFrame(word_counts.items(), columns=[\"word\", \"count\"]).sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Show top and bottom 15\n",
    "print(\"Most frequent words:\\n\", freq_df.head(15))\n",
    "print(\"\\nLeast frequent words:\\n\", freq_df.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39",
    "outputId": "0816d5b5-097a-42c4-9f35-a6f1f6fdb6f1"
   },
   "outputs": [],
   "source": [
    "# Now let's see the top 5 words per stereotype category:\n",
    "stereotype_top_words = {}\n",
    "\n",
    "# Looping through each stereotype category\n",
    "for cat in sorted(filtered_df[\"stereotype\"].unique()):\n",
    "    cat_sentences = filtered_df[filtered_df[\"stereotype\"] == cat][\"sentence\"]\n",
    "\n",
    "    tokens = []\n",
    "    for sentence in cat_sentences:\n",
    "        tokens.extend(preprocess(sentence))\n",
    "\n",
    "    word_counts = Counter(tokens)\n",
    "    top_words = word_counts.most_common(5)\n",
    "\n",
    "    stereotype_top_words[cat] = top_words\n",
    "\n",
    "for cat, words in stereotype_top_words.items():\n",
    "    print(f\"Stereotype {cat}: {words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "40"
   },
   "source": [
    "The top 5 most frequent words in each stereotype category strongly align with the associated stereotype label. For example, Stereotype 3 (“Women are empathetic and caring”) includes care, help, and children, while Stereotype 10 (“Men are professional”) includes work, job and professional. These lexical patterns validate the mappings I made from StereoSet to GEST, confirming that the merged dataset preserves semantic coherence across categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "41"
   },
   "source": [
    "#### Initial t-SNE plot -> Preview embedding structure before full analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "42"
   },
   "source": [
    "Sources:\n",
    "- https://huggingface.co/docs/transformers/en/model_doc/gpt2\n",
    "- https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2\n",
    "- https://stackoverflow.com/questions/52849890/how-to-implement-t-sne-in-a-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "43"
   },
   "source": [
    "#### Starting with gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "44"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "45"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "46",
    "outputId": "bfb274f8-e681-4222-e7e2-a4a777bfb2fa"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "47"
   },
   "outputs": [],
   "source": [
    "# Getting average-pooled sentence embedding from GPT-2\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        embedding = last_hidden_state.mean(dim=1).squeeze()\n",
    "    return embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "48",
    "outputId": "d814a64a-00fd-4f4d-c546-1745956fd435"
   },
   "outputs": [],
   "source": [
    "# Extracting embeddings for all sentences\n",
    "embeddings = []\n",
    "for sentence in tqdm(filtered_df[\"sentence\"], desc=\"Extracting GPT-2 embeddings\"):\n",
    "    emb = get_embedding(sentence)\n",
    "    embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "49",
    "outputId": "73420471-d9b3-4ecb-af1a-9b0ac7f6bea3"
   },
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings)  # shape = (n_sentences, 768)\n",
    "embeddings_df[\"stereotype\"] = filtered_df[\"stereotype\"].values # added 1 col\n",
    "embeddings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "50"
   },
   "outputs": [],
   "source": [
    "# Applying t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(embeddings_df.iloc[:, :-1]) # select all columns except for stereotype col I added\n",
    "embeddings_df[\"tsne_x\"] = tsne_result[:, 0]\n",
    "embeddings_df[\"tsne_y\"] = tsne_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "51",
    "outputId": "4ca4e15b-765f-4108-9c8d-a23cdc754e8a"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cat in sorted(embeddings_df[\"stereotype\"].unique()):\n",
    "    subset = embeddings_df[embeddings_df[\"stereotype\"] == cat]\n",
    "    plt.scatter(subset[\"tsne_x\"], subset[\"tsne_y\"], label=f\"Cat {cat}\", alpha=0.7)\n",
    "plt.title(\"t-SNE of GPT-2 Embeddings\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "52"
   },
   "source": [
    "I don't see any clusters forming, I think 16 categories might be too many for a 2D representation so that's why they are not separating clearly. Lets try clustering my gender so from categories 1-7 (female stereotypes) and 8-16 (male stereotypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "53",
    "outputId": "3797d666-9f97-4901-c75f-7f941987e5a0"
   },
   "outputs": [],
   "source": [
    "embeddings_df[\"gender_group\"] = embeddings_df[\"stereotype\"].apply(lambda x: \"Women\" if x <= 7 else \"Men\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for group in sorted(embeddings_df[\"gender_group\"].unique()):\n",
    "    subset = embeddings_df[embeddings_df[\"gender_group\"] == group]\n",
    "    plt.scatter(subset[\"tsne_x\"], subset[\"tsne_y\"], label=group, alpha=0.7)\n",
    "plt.title(\"t-SNE of GPT-2 Embeddings by Gender Group\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "id": "54"
   },
   "source": [
    "The t-SNE plot shows overlapping male and female stereotype embeddings in GPT-2, suggesting no clear separation at the sentence level. This motivates deeper analysis (e.g., cosine similarity, prompt completions) to uncover more subtle forms of gender bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "id": "55"
   },
   "source": [
    "### Now LLaMA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "a53399612b7e41208621e9240dc76af3",
      "e21bd37ed9b7408eab38a9faf70df26c",
      "a7dca8c7a82741899f09dcde0efc2845",
      "4f57ce1cc35f41caafd01ca8d6ff9e7a",
      "e79cac94b0734f7da19129b798559d8d",
      "24115510a6e14b64bf9c10c117027b83",
      "2b41b474325e4d2eaa32c465115af880",
      "c0b089ec9fce4c4cb994abbd9b6c114e",
      "a2f32f73f54c416eb6d3fb669eaa9354",
      "a85441cd67304342a6318090361948de",
      "9e7e0d9412714aca9c4ffbe1724ffc7b",
      "bf61d4f25d8d4c93bd06c48a0f13d128",
      "9ddb5f923cf04df2bf34fad20b793ab7",
      "0e24c95e5a804379a37914e3f078e73c",
      "72aa90d5ecfe49da8ccc5b646d378aaf",
      "e9905301e855407c9fe54c2e824fa436",
      "ce105fb491654194b110951b3811e42d",
      "36a93de065c049348b91d6fa71663e9b",
      "c36b5e51ca9d430cba73938b5b8ea327",
      "0b4e0f42498d4db8a9d8b6d0fb2531c1"
     ]
    },
    "id": "56",
    "outputId": "cc8c7dae-b604-4ad7-a187-891782495411"
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 970,
     "referenced_widgets": [
      "919b8a2030f944e8ae0d03bfbf9302ed",
      "7de078b644e64daaa632b6e1b4ece1be",
      "654fb64ff70f4085b8008e91a58a80c3",
      "88388b09506940b99881645727f5c1f0",
      "488b8d71d8474257a7e171a6e44bc058",
      "0fc2cab7df2845e0a6d9b79eab6c1d11",
      "bdd69df01eaf48a4ac36c93e6a361352",
      "9b79de8497f94e85b60221a84230a5cb",
      "7210a2563d2e4abd9739d78a884bf9bc",
      "a9b657449c144b318dc59afa0abbccfd",
      "1e9dc7d3b0dd4204bdf6a7e5598eb94b",
      "371a63d1d954484da1eaaaebbb713162",
      "7ab6bf3e17c84367a031399b15cfbb40",
      "fb74e922367242e684913f0788e447bd",
      "52c07b3d38d04ca190a2e4fa9f16aab5",
      "6ff1ddee19bc4af0a71e4e14720916c7",
      "202eb6adc31b485e80c37f596110595a",
      "9891110e909c4265a1a4ac3f102ab9f6",
      "abe47bc91f1d47ecaf9d1657003d4a2d",
      "d6b1a604877140bfb3f4beb790833020",
      "0e2bdb1fa0fe412eaf5798e051319d26",
      "5b5c89ca5d4c4e2dad33f77bcfc82570",
      "56e8bcd1fbdf4e7daf5b42ec8d919e87",
      "8325e2263f1a491ea9bf1779603ba24a",
      "964359771cf444e0861591b21b2a033a",
      "54ecd03ba2c74c18b3402ea199d38afd",
      "0347d91c3ae742069092838da504b25e",
      "5766cf4afbd84086a6d845f3ce1712c0",
      "c3fbf32d0d444d07bacf0851ce50156a",
      "7fa66829f91b4a159b51bf252fa19e4e",
      "b3cff9a2bb7b4ec8840e479103b90c8e",
      "529f5e6dc5c74ad6aab7c0ed9b96c339",
      "ee9f2a82cdc045d086f9bb5804a0cd36",
      "a1ecf456eb9743b6b07342f3ea96703e",
      "bf244cb994a74829aefbb06f20a6949d",
      "c44683b31de141739d5e3016c4bf1f1f",
      "7f7a9b2f579f405988caadf3a6c40731",
      "1173ec19878f4afdb11138621cfc13a4",
      "9b249967b374425bae323d6c74956ffa",
      "b1013c6aa481404ba863c534925d4129",
      "6eae3b9f69bf481a95135a15c0ba2585",
      "a85cf5e5cef14ca495546a5b649e0846",
      "888a3a97e55149a7924678fb182e3f60",
      "91ec2bd3278b4ae3a08b5eac3d4b04ed",
      "a8c6f0a8f86145d881b2280af7f66cfc",
      "155cb9dd8891404d89c46abb88fa3491",
      "0941feaa1f1a4088a01889bb2577b1c0",
      "bf03caf5b94b42c8be480a6107a24fec",
      "a378b7421e204d419d5e9bd7a795fd3c",
      "f8b43c5102a64c3795f95d97f589be02",
      "edf3b4e04443477db152e07f12274339",
      "fa958a8b52e24c02bf04d6aa6ed36f49",
      "3dccccbd2cfb460896922ce935f75cdc",
      "195e481f870a4b5084a0e12ab622a945",
      "03483b57285847e3a415449991ea98b1",
      "10bcc769e2f648cf9728fbb86fddc2b5",
      "8b4e95d8c6d348819c24f57d663e4016",
      "1a0b8d406b30428dbf389ff73520c184",
      "958b171acbb841c19fe576b3ee5c9a83",
      "816d7bd18fa244259e9fb1e90e8f5b6e",
      "b2c21e1c0ee4448a9ec0d091aed7c1f8",
      "67a2b3c98935440c9f00d18bf6527cc5",
      "07a2d93d1f26492f9169318e47199b03",
      "efcf1d604d78483d91d5630cf385904d",
      "0e95ef764dbf40119409ac029a076bb7",
      "3cc9667ab880491d8cd1cb963a4b5b61",
      "65251810124a4be596551436ec35fe02",
      "1d3f74df592347288922933cbc08456b",
      "f8de6412f65440cea1fc36daf4bdd3b4",
      "43a0ab5e026949fda0406693e92b2f31",
      "9fc76b1243c243078f990262f457a39b",
      "ccd5f01e808e458abe13a3b549ed5c6d",
      "26d9d3f4cb5645ca878c800c7c751a1f",
      "fed1fdaed15e4593817a8dd336640c63",
      "9349cd8919ba4c9a878eebb21fe484d8",
      "5c0b6c3ea56c438b854c0f1fe244b8ad",
      "fb1d353e66e04e0ab0a41c4e82f55cc7",
      "44aae4dac5a24f70803a0d000c287ca8",
      "f108600ce2274076ad3de605963ce791",
      "853c5bfb5f14432b80ac793f1855d0e1",
      "30856caefe374c3092b7f14c7f553fc0",
      "84c54c1522ce4c7f884ad38db16ef185",
      "bd07abe897ae4850a6a7f8e461b6eaa5",
      "ec47443629274cc4b52aa60f93aa3570",
      "5fd5deabdfd74a608594d562cd962ef5",
      "4875b07ec7cd4ce9945f95b5ddabcccd",
      "ca85a42f19214e2dbf195fae60a34197",
      "61e0a325356f49bb9e6a2707608a40b7",
      "549aa6942f7f46cf8ac225e03f76b01d",
      "b3accd43d13840409bdf9fc1b798bffd",
      "149b0bee1473443f95552de3a0a31c3d",
      "1f20285d070c4e50b517c0b16b7fbc71",
      "361fc4ace403474a855bfd64f319c77f",
      "81b290e2d2ce4e8994779df27b811c89",
      "3cba37d9477f46059d8b049b2634174f",
      "36c6d862d50b43028c02346a327d853a",
      "8e46aab1d5204d198e516a028ef13fb9",
      "9fae82a05c614609a5a713d15bddbf6d",
      "c5aceddd7761421c9237f2c5375b77e5",
      "01bdbf4e81674eeca06d77ba0673d7f7",
      "0855960ede184b56943bfe28e7696757",
      "04ccf40799e940cb936f91b219a0e760",
      "cc1723f40f9440a7b8a7ec95037705c9",
      "043d12b3fbc14a9abc6a2be46b781638",
      "e17a6f9b390b4d4fb2833162be4fc114",
      "aba593afc0fd4fe3ad10143a28abe72a",
      "829bdb30b7f5402490bd5c8aabd0ff3e",
      "d62eaedf5b1a4ad58ea035fd7fab21f0",
      "08d11d21ead34bd9aca19229c7d28528",
      "e697449991b943da98139ad5b6098e7c",
      "a79b3274783b476f827e5f4453081925",
      "4c7e4687778a4326b0700b149b24abb3",
      "215f5f48904e455c9080334b07b420a3",
      "acb9eedd0ee443edb197af9853038613",
      "ab31f85d6c3046b295e3a9c42159e7af",
      "866b169558704b97a90b1acf01274de0",
      "a1ae7b1d2c1d41f781f9cf4c34710bf4",
      "2cc9735705fc4e3fa354c6f1a39c82a2",
      "b32bbfe03afc46808d584d9d435e5a3a",
      "61332912674f4d30894b64b99f7e86b1",
      "23e2fbba0cb44259b4c6855631e7687d"
     ]
    },
    "id": "57",
    "outputId": "b772cca0-403f-49d8-96dc-6655d80a4296"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"            # automatically sends model to GPU if available\n",
    ")\n",
    "llama_model.eval()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58",
    "outputId": "0cb560f5-37ee-4678-c45a-fb001ba748fe"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# llama_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59",
    "outputId": "5dc6046c-4f63-4616-9385-5f82cae1d618"
   },
   "outputs": [],
   "source": [
    "# # Getting average-pooled sentence embedding from LlaMA-2 -> similar struct to gpt-2 but the hidden layers are called differently\n",
    "def get_llama2_embedding(text, model, tokenizer, device):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states[-1]  # last layer\n",
    "        embedding = hidden_states.mean(dim=1).squeeze()\n",
    "    return embedding.cpu().numpy()\n",
    "\n",
    "# Extracting embeddings for all sentences\n",
    "llama_embeddings = []\n",
    "for sentence in tqdm(filtered_df[\"sentence\"], desc=\"Extracting LLaMA embeddings\"):\n",
    "    emb = get_llama2_embedding(sentence, llama_model, llama_tokenizer, device)\n",
    "    llama_embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60",
    "outputId": "075a0a24-4afc-41d4-915d-443569c63b76"
   },
   "outputs": [],
   "source": [
    "embeddings_llama = pd.DataFrame(llama_embeddings)  # shape\n",
    "embeddings_llama[\"stereotype\"] = filtered_df[\"stereotype\"].values # added 1 col\n",
    "embeddings_llama.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "id": "61"
   },
   "outputs": [],
   "source": [
    "# Applying t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(embeddings_llama.iloc[:, :-1]) # select all columns except for stereotype col I added\n",
    "embeddings_llama[\"tsne_x\"] = tsne_result[:, 0]\n",
    "embeddings_llama[\"tsne_y\"] = tsne_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "62",
    "outputId": "8bfb1f78-60f1-4c1a-af08-b392022f67e6"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cat in sorted(embeddings_llama[\"stereotype\"].unique()):\n",
    "    subset = embeddings_llama[embeddings_llama[\"stereotype\"] == cat]\n",
    "    plt.scatter(subset[\"tsne_x\"], subset[\"tsne_y\"], label=f\"Cat {cat}\", alpha=0.7)\n",
    "plt.title(\"t-SNE of LlaMA Embeddings\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "id": "63"
   },
   "source": [
    "Compared to GPT-2, the t-SNE plots for LLaMA-2 embeddings show a bit more structure. For example, there’s a noticeable cluster of points from Category 16 (e.g., “Men are strong”) between -20 and 0 on the t-SNE 1 axis. Right next to it, there's also a small grouping for Category 14 (“Men are childish”), which might suggest some overlap in how these stereotypes are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "64",
    "outputId": "8ccebeb6-fbd3-46d5-ba1f-28ee73b50484"
   },
   "outputs": [],
   "source": [
    "embeddings_llama[\"gender_group\"] = embeddings_llama[\"stereotype\"].apply(lambda x: \"Women\" if x <= 7 else \"Men\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for group in sorted(embeddings_llama[\"gender_group\"].unique()):\n",
    "    subset = embeddings_llama[embeddings_llama[\"gender_group\"] == group]\n",
    "    plt.scatter(subset[\"tsne_x\"], subset[\"tsne_y\"], label=group, alpha=0.7)\n",
    "plt.title(\"t-SNE of LLaMA-2 Embeddings by Gender Group\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "id": "65"
   },
   "source": [
    "In this plot, the orange dots (Women) seem to concentrate more around the middle-left of the plot (roughly t-SNE 1 from 0 to 20 and t-SNE 2 from -20 to -40), while some blue areas (Men) show up on the far right (t-SNE 1 from 40 to 60). It’s not a perfect separation, but it's clearer than what I observed with GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "id": "66"
   },
   "source": [
    "This suggests that LLaMA-2 might already be encoding some gender-related differences in its embeddings. So even before doing anything more complex like cosine similarity or prompt completions, the embeddings already hint at underlying biases — which makes a stronger case for looking deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "id": "67"
   },
   "source": [
    "### Conclusions from EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "id": "68"
   },
   "source": [
    "##### - Stereotype Category Distribution:\n",
    "    - All 16 stereotype categories are well represented in the dataset, ranging from 206 to 290 instances each.\n",
    "    - No major imbalances were found, which ensures fairness and robustness for downstream analysis.\n",
    "##### - Sentence Length Distribution:\n",
    "    - Most sentences are around 5-15 words long.\n",
    "    - A few outliers (very short or very long sentences) were identified and removed (~110 sentences) to prevent noise in embedding generation.\n",
    "##### - Word Frequency Analysis:\n",
    "    - Words like care, home, and felt were more common in Women stereotypes, while work, money, and team were more frequent in Men stereotypes.\n",
    "    - Per-category analysis further confirmed that the most frequent words aligned well with the stereotype labels, validating the mapping from StereoSet to GEST.\n",
    "##### - t-SNE Visualization – GPT-2 vs LLaMA-2 Embeddings:\n",
    "    - GPT-2 embeddings showed little structure; all stereotype categories and gender groups were highly intermixed.\n",
    "    - LLaMA-2 embeddings revealed more noticeable clusters. This clustering suggests that LLaMA-2 is already encoding stereotypical signals in its internal representation space — even before any generation or classification step.\n",
    "##### - Justification of research question:\n",
    "    - These EDA results provide early evidence that large language models like LLaMA-2 may internalize gender biases at the embedding level.\n",
    "    - The differences between GPT-2 and LLaMA-2 also highlight the potential impact of instruction tuning on how stereotypes are encoded.\n",
    "    - This strongly justifies a deeper investigation into how and where gender stereotypes are represented — comparing both prompt-based outputs and internal embeddings — as outlined in the rest of the study."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:neuralnetworks]",
   "language": "python",
   "name": "conda-env-neuralnetworks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
