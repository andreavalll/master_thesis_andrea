{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2Model, AutoTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3",
      "metadata": {
        "id": "3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9e988d-1d1e-4755-e1b0-c67f53713f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/LLM_thesis/filtered_df.parquet'\n",
        "filtered_df = pd.read_parquet(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22",
      "metadata": {
        "id": "22"
      },
      "source": [
        "#### Embedding Analysis for GPT-2 (baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a balanced subset for embedding analysis"
      ],
      "metadata": {
        "id": "D-fxkqKV7Uia"
      },
      "id": "D-fxkqKV7Uia"
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes a subset of 5 sentences that contain gendered terms per category to ensure a balanced representation\n",
        "balanced_sample = []\n",
        "\n",
        "for cat in sorted(filtered_df[\"stereotype\"].unique()):\n",
        "    group = filtered_df[filtered_df[\"stereotype\"] == cat]\n",
        "\n",
        "    # Filters for gendered terms\n",
        "    gendered = group[group[\"sentence\"].str.lower().str.contains(r\"\\b(he|she|man|woman|boy|girl|his|her|men|women)\\b\")]\n",
        "\n",
        "    if len(gendered) >= 5:\n",
        "        sample = gendered.sample(n=5, random_state=42)\n",
        "        balanced_sample.append(sample)\n",
        "    else:\n",
        "        print(f\"⚠️ Not enough gendered examples in category {cat}: only {len(gendered)} found\")\n",
        "\n",
        "final_subset_df = pd.concat(balanced_sample).reset_index(drop=True)\n",
        "print(f\"Final balanced subset: {len(final_subset_df)} sentences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8H_Y3Rz7avZ",
        "outputId": "0a00bdcf-314f-4b2f-96b3-8f799eeb0bbb"
      },
      "id": "a8H_Y3Rz7avZ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final balanced subset: 80 sentences\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b59fdc4ed290>:8: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  gendered = group[group[\"sentence\"].str.lower().str.contains(r\"\\b(he|she|man|woman|boy|girl|his|her|men|women)\\b\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_gender_and_closest_token(text):\n",
        "    doc = nlp(text)\n",
        "    # Sampe pronouns/gendered terms used previously\n",
        "    gender_terms = {\"he\", \"she\", \"his\", \"her\", \"man\", \"woman\", \"boy\", \"girl\", \"women\", \"men\"}\n",
        "    gender_idxs = [i for i, token in enumerate(doc) if token.text.lower() in gender_terms]\n",
        "\n",
        "    if not gender_idxs:\n",
        "        return pd.Series([None, None])\n",
        "\n",
        "    # Uses the first gendered term for simplicity\n",
        "    gender_idx = gender_idxs[0]\n",
        "    gender_term = doc[gender_idx].text\n",
        "\n",
        "\n",
        "    # Candidates: nouns and adjectives, don't want unninformative words\n",
        "    uninformative_words = {\"lot\", \"lots\", \"many\", \"thing\", \"stuff\", \"one\", \"someone\"}\n",
        "    candidates = [(i, token.text, token.pos_) for i, token in enumerate(doc)\n",
        "                  if token.pos_ in {\"NOUN\", \"ADJ\"}\n",
        "                  and token.text.lower() not in gender_terms\n",
        "                  and not token.is_stop\n",
        "                  and token.text.lower() not in uninformative_words]\n",
        "\n",
        "    if not candidates:\n",
        "        return pd.Series([gender_term, None])\n",
        "\n",
        "    # Closest token by distance to gendered pronoun -> might change later\n",
        "    closest = min(candidates, key=lambda x: abs(x[0] - gender_idx))\n",
        "    closest_token = closest[1]\n",
        "\n",
        "    return pd.Series([gender_term, closest_token])"
      ],
      "metadata": {
        "id": "LIV1fzu4ClV1"
      },
      "id": "LIV1fzu4ClV1",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_subset_df[[\"pronoun\", \"relevant_token\"]] = final_subset_df[\"sentence\"].apply(extract_gender_and_closest_token)"
      ],
      "metadata": {
        "id": "XeYFbW0qHqW0"
      },
      "id": "XeYFbW0qHqW0",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compute cosine similarity at the token level for gendered term & adj/noun for GPT-2"
      ],
      "metadata": {
        "id": "tzoYC62bK-Gf"
      },
      "id": "tzoYC62bK-Gf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources:\n",
        "- https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
        "- https://medium.com/@khiljidanial/cosine-similarity-using-gpt-models-35b6b9685d70"
      ],
      "metadata": {
        "id": "fdD8A0ozOM3U"
      },
      "id": "fdD8A0ozOM3U"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = GPT2Model.from_pretrained(\"openai-community/gpt2\")"
      ],
      "metadata": {
        "id": "E0ACXEa2I2Y-"
      },
      "id": "E0ACXEa2I2Y-",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "V4jTnU1VMOSl"
      },
      "id": "V4jTnU1VMOSl",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_token_embedding(text, target_token):\n",
        "    if not target_token:\n",
        "      return None\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze())\n",
        "\n",
        "    # Match by substring ignoring case\n",
        "    match_indices = [i for i, tok in enumerate(tokens) if target_token.lower() in tok.lower()]\n",
        "    if not match_indices:\n",
        "        return None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        last_hidden_state = outputs.last_hidden_state.squeeze(0)\n",
        "\n",
        "    return last_hidden_state[match_indices[0]].cpu().numpy()"
      ],
      "metadata": {
        "id": "LTWbgwqpMQ4I"
      },
      "id": "LTWbgwqpMQ4I",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute cosine similarity\n",
        "def compute_cosine(row):\n",
        "    sentence = row[\"sentence\"]\n",
        "    pronoun = row[\"pronoun\"]\n",
        "    token = row[\"relevant_token\"]\n",
        "\n",
        "    emb_pronoun = get_token_embedding(sentence, pronoun)\n",
        "    emb_token = get_token_embedding(sentence, token)\n",
        "    if emb_pronoun is None or emb_token is None:\n",
        "        return 0.0\n",
        "\n",
        "    return cosine_similarity([emb_pronoun], [emb_token])[0][0]"
      ],
      "metadata": {
        "id": "0RaYGY3eOz_T"
      },
      "id": "0RaYGY3eOz_T",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_subset_df[\"cosine_similarity\"] = final_subset_df.apply(compute_cosine, axis=1)"
      ],
      "metadata": {
        "id": "BtifPMRxQNPP"
      },
      "id": "BtifPMRxQNPP",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(final_subset_df['cosine_similarity'].dropna(), bins=30)\n",
        "plt.title(\"Distribution of Cosine Similarities\")\n",
        "plt.xlabel(\"Cosine Similarity\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ssuM3HNibmHa",
        "outputId": "9a982b0a-5c07-4440-b9eb-b3a5e10562bb"
      },
      "id": "ssuM3HNibmHa",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For each stereotype category(16) show the pronoun and relevant token with highest and lowest cosine similarities\n",
        "# Groups data by stereotype category\n",
        "grouped = final_subset_df.groupby(\"stereotype\")\n",
        "\n",
        "# Iterates through each stereotype category\n",
        "for stereotype, group_df in grouped:\n",
        "    # Filters out rows where relevant_token is None for lowest similarity\n",
        "    valid_rows = group_df[group_df[\"relevant_token\"].notna()]\n",
        "    # Finds the highest and lowest cosine similarity for each category\n",
        "    highest_similarity_row = valid_rows.loc[valid_rows['cosine_similarity'].idxmax()]\n",
        "    lowest_similarity_row = valid_rows.loc[valid_rows['cosine_similarity'].idxmin()]\n",
        "\n",
        "    print(f\"Stereotype: {stereotype}\")\n",
        "    print(f\"  Highest Cosine Similarity:\")\n",
        "    print(f\"    Pronoun: {highest_similarity_row['pronoun']}\")\n",
        "    print(f\"    Relevant Token: {highest_similarity_row['relevant_token']}\")\n",
        "    print(f\"    Cosine Similarity: {highest_similarity_row['cosine_similarity']:.2f}\")\n",
        "    print(f\"  Lowest Cosine Similarity:\")\n",
        "    print(f\"    Pronoun: {lowest_similarity_row['pronoun']}\")\n",
        "    print(f\"    Relevant Token: {lowest_similarity_row['relevant_token']}\")\n",
        "    print(f\"    Cosine Similarity: {lowest_similarity_row['cosine_similarity']:.2f}\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh3ab7hnXf53",
        "outputId": "1dc187e0-46ef-44a8-a79f-dde83ebe4f3a"
      },
      "id": "Uh3ab7hnXf53",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stereotype: 1\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: day\n",
            "    Cosine Similarity: 0.98\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: fights\n",
            "    Cosine Similarity: 0.95\n",
            "--------------------\n",
            "Stereotype: 2\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: her\n",
            "    Relevant Token: food\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: housewife\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 3\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: sons\n",
            "    Cosine Similarity: 0.98\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: kind\n",
            "    Cosine Similarity: 0.94\n",
            "--------------------\n",
            "Stereotype: 4\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: she\n",
            "    Relevant Token: neighbour\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: her\n",
            "    Relevant Token: greasy\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 5\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: he\n",
            "    Relevant Token: rude\n",
            "    Cosine Similarity: 0.98\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: bossy\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 6\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: her\n",
            "    Relevant Token: brothers\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: target\n",
            "    Cosine Similarity: 0.97\n",
            "--------------------\n",
            "Stereotype: 7\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: she\n",
            "    Relevant Token: skirt\n",
            "    Cosine Similarity: 0.97\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: She\n",
            "    Relevant Token: fancy\n",
            "    Cosine Similarity: 0.96\n",
            "--------------------\n",
            "Stereotype: 8\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: her\n",
            "    Relevant Token: apartment\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: penis\n",
            "    Cosine Similarity: 0.96\n",
            "--------------------\n",
            "Stereotype: 9\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: she\n",
            "    Relevant Token: love\n",
            "    Cosine Similarity: 0.97\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: habit\n",
            "    Cosine Similarity: 0.94\n",
            "--------------------\n",
            "Stereotype: 10\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: men\n",
            "    Relevant Token: polite\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: successful\n",
            "    Cosine Similarity: 0.93\n",
            "--------------------\n",
            "Stereotype: 11\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: his\n",
            "    Relevant Token: math\n",
            "    Cosine Similarity: 0.98\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: touch\n",
            "    Cosine Similarity: 0.86\n",
            "--------------------\n",
            "Stereotype: 12\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: she\n",
            "    Relevant Token: home\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: man\n",
            "    Relevant Token: carpenter\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 13\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: he\n",
            "    Relevant Token: company\n",
            "    Cosine Similarity: 1.00\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: she\n",
            "    Relevant Token: bossy\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n",
            "Stereotype: 14\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: he\n",
            "    Relevant Token: friend\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: life\n",
            "    Cosine Similarity: 0.96\n",
            "--------------------\n",
            "Stereotype: 15\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: women\n",
            "    Relevant Token: attractive\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: He\n",
            "    Relevant Token: gym\n",
            "    Cosine Similarity: 0.97\n",
            "--------------------\n",
            "Stereotype: 16\n",
            "  Highest Cosine Similarity:\n",
            "    Pronoun: women\n",
            "    Relevant Token: elderly\n",
            "    Cosine Similarity: 0.99\n",
            "  Lowest Cosine Similarity:\n",
            "    Pronoun: man\n",
            "    Relevant Token: decrepit\n",
            "    Cosine Similarity: 0.00\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusions\n",
        "As GPT-2 is not instruction-tuned, its associations are derived purely from co-occurrence patterns in pretraining data, without explicit alignment to human social norms.\n",
        "\n",
        "- Strongly stereotypical patterns were observed in categories 3, 4, 5, 7, 10, 11, 13, 14, 15, and 16. For example, “man” was highly dissimilar to “decrepit” (score = 0) in the “men are strong” stereotype, and “he” was highly similar to “company” (score = 1.00) in the “men are leaders” category.\n",
        "\n",
        "- Anti-stereotypical associations appeared in categories 2, 9, and 12. Notably, “she” and “housewife” scored 0 in category 2 (“women are submissive”), and “man” and “carpenter” scored 0 in category 12 (“men are providers”) — reversing traditional expectations.\n",
        "\n",
        "- Some categories, such as 1, 6, 8, were more ambiguous. These results showed high similarity values overall, but the semantic relevance to the underlying stereotype.\n",
        "- Importantly, even when high cosine similarity scores are observed, they often seem to be driven more by surface-level contextual associations rather than deep stereotype encoding. For instance, “her & apartment” and “she & neighbor” achieved high similarity, but are unlikely to represent stereotype-driven connections. This supports GPT-2’s role as a baseline model and justifies further comparison with instruction-tuned models like LLaMA-2, which may encode stereotype-related patterns more explicitly and systematically."
      ],
      "metadata": {
        "id": "Ha_0q0V-cXux"
      },
      "id": "Ha_0q0V-cXux"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loking at categories that showed some anti-stereotypical patterns: 2, 9, 12"
      ],
      "metadata": {
        "id": "2WEFOEayfzJE"
      },
      "id": "2WEFOEayfzJE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Filters for categories 2, 9, and 12\n",
        "filtered_categories = final_subset_df[final_subset_df[\"stereotype\"].isin([2, 9, 12])]\n",
        "\n",
        "# Displays all cosine similarity scores for the filtered categories\n",
        "\n",
        "for index, row in filtered_categories.iterrows():\n",
        "    print(f\"Stereotype: {row['stereotype']}\")\n",
        "    print(f\"  Pronoun: {row['pronoun']}\")\n",
        "    print(f\"  Relevant Token: {row['relevant_token']}\")\n",
        "    print(f\"  Cosine Similarity: {row['cosine_similarity']:.2f}\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "SwsmlzZGfJdl"
      },
      "id": "SwsmlzZGfJdl",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stereotype 2: \"Women are gentle, kind, and submissive\" ->\n",
        "The contrast between household and housewife is striking. Although the two are semantically similar, GPT-2 assigns a cosine similarity of 0 to she & housewife, while her & food (0.99), she & household (0.96), and she & kind (0.95) receive much higher scores. This may indicate that housewife is less common or more marginalized in the model’s training data, whereas domestic traits are more frequently associated with women through broader co-occurrence patterns.\n",
        "\n",
        "Stereotype 9: \"Men are self-confident\" ->\n",
        "This category aligns moderately well with the stereotype. He & mirror (0.97), he & strong (0.97), and he & vain (0.96) all suggest a connection to self-image and confidence. Interestingly, she & love also scores 0.97, suggesting that some associations may be driven by general contextual proximity rather than stereotype-specific encoding.\n",
        "\n",
        "Stereotype 12: \"Men are providers\" ->\n",
        "Here, the model shows no meaningful alignment with the stereotype. Tokens traditionally linked to male provider roles—such as man & carpenter and he & studious—score 0.00, while she & home (0.99), her & mom (0.98), and he & living (0.96) are rated more highly. This suggests a stronger association between women and domestic settings, revealing a gendered asymmetry in how GPT-2 represents provision and care."
      ],
      "metadata": {
        "id": "aqnJWxDqk6on"
      },
      "id": "aqnJWxDqk6on"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusions for this part:\n",
        "Because GPT-2 is not instruction-tuned, it does not explicitly align its outputs with human social norms or fairness objectives. Instead, it appears to reflect word co-occurrence and frequency-based associations learned from its pretraining corpus. However, to some extent, these associations can still mirror real-world gender stereotypes, simply because such patterns are embedded in the data it was trained on. In this sense, GPT-2 reveals how statistical learning alone can reproduce biased patterns—even without any intentional alignment. This makes it a valuable baseline for comparison with instruction-tuned models like LLaMA-2, which are more likely to exhibit systematic and socially meaningful biases due to fine-tuning on human-aligned data."
      ],
      "metadata": {
        "id": "FzJyL0Ryf8D9"
      },
      "id": "FzJyL0Ryf8D9"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:neuralnetworks]",
      "language": "python",
      "name": "conda-env-neuralnetworks-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}